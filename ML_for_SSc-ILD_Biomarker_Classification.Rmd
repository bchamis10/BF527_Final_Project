---
title: "Machine Learning for SSc-ILD Biomarker Classification"
output: html_document
---

```{r setup, message=FALSE, warning=FALSE}
# ---- Load packages ----
library(dplyr)
library(tidyr)
library(ggplot2)
library(caret)           # Machine learning framework
library(randomForest)    # Random Forest
library(e1071)           # SVM
library(pROC)            # ROC curves
library(ggpubr)          # Publication plots
library(pheatmap)        # Heatmaps

set.seed(42)  # For reproducibility
```

```{r prepare-full-data}
# ---- Prepare FULL data for ML (all genes, not just genes of interest) ----
# This uses ALL genes from your expression data, not just the 8 genes of interest
# This allows the ML model to learn from the complete transcriptomic signature

# GSE76808 - all genes
GSE76808_all <- GSE76808_mapped %>%
  dplyr::select(-ProbeID) %>%
  group_by(Gene) %>%
  summarize(across(where(is.numeric), mean), .groups = "drop")

GSE76808_all_long <- GSE76808_all %>%
  pivot_longer(cols = -Gene, names_to = "Sample", values_to = "Expression") %>%
  left_join(metadata, by = "Sample") %>%
  filter(!is.na(Condition))

# GSE48149 - all genes
GSE48149_all <- GSE48149_mapped %>%
  dplyr::select(-ProbeID) %>%
  group_by(Gene) %>%
  summarize(across(where(is.numeric), mean), .groups = "drop")

GSE48149_all_long <- GSE48149_all %>%
  pivot_longer(cols = -Gene, names_to = "Sample", values_to = "Expression") %>%
  left_join(metadata, by = "Sample") %>%
  filter(!is.na(Condition))

# GSE81292 - all genes
GSE81292_all <- GSE81292_mapped %>%
  dplyr::select(-ProbeID) %>%
  group_by(Gene) %>%
  summarize(across(where(is.numeric), mean), .groups = "drop")

GSE81292_all_long <- GSE81292_all %>%
  pivot_longer(cols = -Gene, names_to = "Sample", values_to = "Expression") %>%
  left_join(metadata, by = "Sample") %>%
  filter(!is.na(Condition))

cat("GSE76808 - Total genes:", n_distinct(GSE76808_all_long$Gene), "\n")
cat("GSE48149 - Total genes:", n_distinct(GSE48149_all_long$Gene), "\n")
cat("GSE81292 - Total genes:", n_distinct(GSE81292_all_long$Gene), "\n\n")
```

```{r prepare-ml-data}
# ---- Convert to ML format ----
# Convert long format to wide format (samples as rows, genes as columns)

prepare_ml_data <- function(expr_long, dataset_name) {
  expr_wide <- expr_long %>%
    dplyr::select(Gene, Sample, Expression, Condition) %>%
    pivot_wider(names_from = Gene, values_from = Expression) %>%
    mutate(Dataset = dataset_name,
           # Replace hyphen with underscore for valid R variable names
           Condition = factor(Condition, levels = c("control", "SSc-ILD"),
                            labels = c("control", "SSc_ILD"))) %>%
    filter(!is.na(Condition))
  
  return(expr_wide)
}

# Prepare each dataset
ml_76808 <- prepare_ml_data(GSE76808_all_long, "GSE76808")
ml_48149 <- prepare_ml_data(GSE48149_all_long, "GSE48149")
ml_81292 <- prepare_ml_data(GSE81292_all_long, "GSE81292")

# Find genes present in ALL three datasets for fair comparison
common_genes <- Reduce(intersect, list(
  setdiff(colnames(ml_76808), c("Sample", "Condition", "Dataset")),
  setdiff(colnames(ml_48149), c("Sample", "Condition", "Dataset")),
  setdiff(colnames(ml_81292), c("Sample", "Condition", "Dataset"))
))

cat("Genes present in all datasets:", length(common_genes), "\n")
cat("First 10 common genes:", paste(head(common_genes, 10), collapse = ", "), "\n\n")

# Keep only common genes
ml_76808 <- ml_76808 %>% dplyr::select(Sample, Condition, Dataset, all_of(common_genes))
ml_48149 <- ml_48149 %>% dplyr::select(Sample, Condition, Dataset, all_of(common_genes))
ml_81292 <- ml_81292 %>% dplyr::select(Sample, Condition, Dataset, all_of(common_genes))

# Combine all datasets
ml_combined <- bind_rows(ml_76808, ml_48149, ml_81292)

cat("Combined dataset dimensions:", nrow(ml_combined), "samples x", length(common_genes), "genes\n")
cat("Class distribution:\n")
print(table(ml_combined$Condition, ml_combined$Dataset))
```

```{r scale-data}
# ---- Scale expression data ----
# Important: Different platforms have different scales
# We'll scale each dataset separately to account for batch effects

ml_scaled <- ml_combined %>%
  group_by(Dataset) %>%
  mutate(across(all_of(common_genes), ~scale(.)[,1])) %>%
  ungroup()

# Prepare feature matrix and labels
X <- ml_scaled %>% dplyr::select(all_of(common_genes)) %>% as.data.frame()
y <- ml_scaled$Condition
dataset_labels <- ml_scaled$Dataset
```

```{r within-dataset-cv}
# ---- Within-Dataset Cross-Validation ----
# Train and test on each dataset separately using 5-fold CV

train_within_dataset <- function(data, dataset_name) {
  cat("\n=== Training on", dataset_name, "===\n")
  
  X_subset <- data %>% dplyr::select(all_of(common_genes)) %>% as.data.frame()
  y_subset <- data$Condition
  
  # Check sample sizes
  n_samples <- nrow(data)
  class_counts <- table(y_subset)
  cat("Sample sizes:", paste(names(class_counts), "=", class_counts, collapse = ", "), "\n")
  
  # Use 3-fold CV for small datasets, 5-fold for larger ones
  n_folds <- ifelse(min(class_counts) < 10, 3, 5)
  cat("Using", n_folds, "-fold cross-validation\n")
  
  # Set up cross-validation
  train_control <- trainControl(
    method = "cv",
    number = n_folds,
    summaryFunction = twoClassSummary,
    classProbs = TRUE,
    savePredictions = "final"
  )
  
  # Random Forest
  cat("Training Random Forest...\n")
  rf_model <- train(
    x = X_subset,
    y = y_subset,
    method = "rf",
    trControl = train_control,
    metric = "ROC",
    ntree = 500
  )
  
  # SVM
  cat("Training SVM...\n")
  svm_model <- train(
    x = X_subset,
    y = y_subset,
    method = "svmRadial",
    trControl = train_control,
    metric = "ROC",
    preProcess = c("center", "scale")
  )
  
  # Logistic Regression with LASSO (only if sufficient samples)
  lr_model <- NULL
  if (n_samples >= 30 && min(class_counts) >= 8) {
    cat("Training Logistic Regression with LASSO...\n")
    lr_model <- train(
      x = X_subset,
      y = y_subset,
      method = "glmnet",
      family = "binomial",
      trControl = train_control,
      metric = "ROC",
      tuneGrid = expand.grid(alpha = 1, lambda = seq(0.001, 0.1, length = 10))
    )
  } else {
    cat("Skipping Logistic Regression - insufficient samples (need ≥30 total, ≥8 per class)\n")
  }
  
  return(list(
    rf = rf_model,
    svm = svm_model,
    lr = lr_model,
    dataset = dataset_name
  ))
}

# Train on each dataset
results_76808 <- train_within_dataset(ml_76808, "GSE76808")
results_48149 <- train_within_dataset(ml_48149, "GSE48149")
results_81292 <- train_within_dataset(ml_81292, "GSE81292")

# Collect performance metrics
collect_metrics <- function(results) {
  # Handle case where lr_model might be NULL
  if (is.null(results$lr)) {
    data.frame(
      Dataset = results$dataset,
      Model = c("Random Forest", "SVM"),
      ROC = c(max(results$rf$results$ROC, na.rm = TRUE),
              max(results$svm$results$ROC, na.rm = TRUE)),
      Sens = c(max(results$rf$results$Sens, na.rm = TRUE),
               max(results$svm$results$Sens, na.rm = TRUE)),
      Spec = c(max(results$rf$results$Spec, na.rm = TRUE),
               max(results$svm$results$Spec, na.rm = TRUE))
    )
  } else {
    data.frame(
      Dataset = results$dataset,
      Model = c("Random Forest", "SVM", "Logistic Regression"),
      ROC = c(max(results$rf$results$ROC, na.rm = TRUE),
              max(results$svm$results$ROC, na.rm = TRUE),
              max(results$lr$results$ROC, na.rm = TRUE)),
      Sens = c(max(results$rf$results$Sens, na.rm = TRUE),
               max(results$svm$results$Sens, na.rm = TRUE),
               max(results$lr$results$Sens, na.rm = TRUE)),
      Spec = c(max(results$rf$results$Spec, na.rm = TRUE),
               max(results$svm$results$Spec, na.rm = TRUE),
               max(results$lr$results$Spec, na.rm = TRUE))
    )
  }
}

within_metrics <- bind_rows(
  collect_metrics(results_76808),
  collect_metrics(results_48149),
  collect_metrics(results_81292)
)

print(within_metrics)
```

```{r cross-dataset-validation}
# ---- Cross-Dataset Validation ----
# Train on one dataset, test on another (most rigorous test!)

cross_validate <- function(train_data, test_data, train_name, test_name) {
  cat("\n=== Train on", train_name, "| Test on", test_name, "===\n")
  
  X_train <- train_data %>% dplyr::select(all_of(common_genes)) %>% as.data.frame()
  y_train <- train_data$Condition
  X_test <- test_data %>% dplyr::select(all_of(common_genes)) %>% as.data.frame()
  y_test <- test_data$Condition
  
  # Train Random Forest
  cat("Training Random Forest...\n")
  rf_model <- randomForest(x = X_train, y = y_train, ntree = 500, importance = TRUE)
  rf_pred <- predict(rf_model, X_test, type = "prob")[, "SSc_ILD"]
  rf_roc <- roc(y_test, rf_pred, levels = c("control", "SSc_ILD"), direction = "<")
  
  # Train SVM
  cat("Training SVM...\n")
  svm_model <- svm(x = X_train, y = y_train, kernel = "radial", probability = TRUE)
  svm_pred <- attr(predict(svm_model, X_test, probability = TRUE), "probabilities")[, "SSc_ILD"]
  svm_roc <- roc(y_test, svm_pred, levels = c("control", "SSc_ILD"), direction = "<")
  
  cat("RF AUC:", round(auc(rf_roc), 3), "| SVM AUC:", round(auc(svm_roc), 3), "\n")
  
  return(list(
    train = train_name,
    test = test_name,
    rf_roc = rf_roc,
    svm_roc = svm_roc,
    rf_model = rf_model
  ))
}

# All pairwise combinations
cross_76808_48149 <- cross_validate(ml_76808, ml_48149, "GSE76808", "GSE48149")
cross_76808_81292 <- cross_validate(ml_76808, ml_81292, "GSE76808", "GSE81292")
cross_48149_76808 <- cross_validate(ml_48149, ml_76808, "GSE48149", "GSE76808")
cross_48149_81292 <- cross_validate(ml_48149, ml_81292, "GSE48149", "GSE81292")
cross_81292_76808 <- cross_validate(ml_81292, ml_76808, "GSE81292", "GSE76808")
cross_81292_48149 <- cross_validate(ml_81292, ml_48149, "GSE81292", "GSE48149")

# Collect cross-validation AUCs
cross_auc <- data.frame(
  Train = c("GSE76808", "GSE76808", "GSE48149", "GSE48149", "GSE81292", "GSE81292"),
  Test = c("GSE48149", "GSE81292", "GSE76808", "GSE81292", "GSE76808", "GSE48149"),
  RF_AUC = c(
    auc(cross_76808_48149$rf_roc), auc(cross_76808_81292$rf_roc),
    auc(cross_48149_76808$rf_roc), auc(cross_48149_81292$rf_roc),
    auc(cross_81292_76808$rf_roc), auc(cross_81292_48149$rf_roc)
  ),
  SVM_AUC = c(
    auc(cross_76808_48149$svm_roc), auc(cross_76808_81292$svm_roc),
    auc(cross_48149_76808$svm_roc), auc(cross_48149_81292$svm_roc),
    auc(cross_81292_76808$svm_roc), auc(cross_81292_48149$svm_roc)
  )
)

print(cross_auc)
```

```{r feature-importance}
# ---- Feature Importance Analysis ----
# Which genes are most important for classification?

# Train final model on all data
X_all <- ml_scaled %>% dplyr::select(all_of(common_genes)) %>% as.data.frame()
y_all <- ml_scaled$Condition

cat("\nTraining final Random Forest on all data...\n")
final_rf <- randomForest(x = X_all, y = y_all, ntree = 500, importance = TRUE)

# Extract importance scores
importance_scores <- data.frame(
  Gene = rownames(importance(final_rf)),
  MeanDecreaseAccuracy = importance(final_rf)[, "MeanDecreaseAccuracy"],
  MeanDecreaseGini = importance(final_rf)[, "MeanDecreaseGini"]
) %>%
  arrange(desc(MeanDecreaseAccuracy))

cat("\nTop 20 most important genes:\n")
print(head(importance_scores, 20))

# Check if your genes of interest are in the top features
genes_of_interest <- c("MMP7", "KRT17", "SPP1", "GDF15", "CDKN2A", "FRZB", "PDE1A", "NAP1L2")
genes_of_interest_present <- intersect(genes_of_interest, common_genes)

if (length(genes_of_interest_present) > 0) {
  cat("\nRanking of your genes of interest:\n")
  interest_ranks <- importance_scores %>%
    mutate(Rank = row_number()) %>%
    filter(Gene %in% genes_of_interest_present) %>%
    dplyr::select(Rank, Gene, MeanDecreaseAccuracy, MeanDecreaseGini)
  print(interest_ranks)
}

# Plot top 20 feature importance
p_importance <- importance_scores %>%
  head(20) %>%
  ggplot(aes(x = reorder(Gene, MeanDecreaseAccuracy), y = MeanDecreaseAccuracy)) +
  geom_col(fill = "steelblue") +
  coord_flip() +
  theme_bw() +
  labs(title = "Top 20 Genes for SSc-ILD Classification",
       subtitle = "Random Forest - Mean Decrease in Accuracy",
       x = "Gene", y = "Importance Score")

print(p_importance)
ggsave("feature_importance_top20.png", p_importance, width = 7, height = 6, dpi = 300)
```

```{r roc-curves}
# ---- Plot ROC Curves ----

# Within-dataset ROC curves
plot_within_roc <- function(results, dataset_name) {
  rf_preds <- results$rf$pred %>% filter(mtry == results$rf$bestTune$mtry)
  rf_roc <- roc(rf_preds$obs, rf_preds$SSc_ILD, levels = c("control", "SSc_ILD"))
  
  svm_preds <- results$svm$pred %>% filter(sigma == results$svm$bestTune$sigma, 
                                           C == results$svm$bestTune$C)
  svm_roc <- roc(svm_preds$obs, svm_preds$SSc_ILD, levels = c("control", "SSc_ILD"))
  
  plot(rf_roc, col = "red", main = paste("ROC Curves -", dataset_name), lwd = 2)
  plot(svm_roc, col = "blue", add = TRUE, lwd = 2)
  
  # Only plot LR if it exists
  legend_items <- c(paste("RF (AUC =", round(auc(rf_roc), 3), ")"),
                    paste("SVM (AUC =", round(auc(svm_roc), 3), ")"))
  legend_cols <- c("red", "blue")
  
  if (!is.null(results$lr)) {
    lr_preds <- results$lr$pred %>% filter(alpha == results$lr$bestTune$alpha,
                                            lambda == results$lr$bestTune$lambda)
    lr_roc <- roc(lr_preds$obs, lr_preds$SSc_ILD, levels = c("control", "SSc_ILD"))
    plot(lr_roc, col = "green", add = TRUE, lwd = 2)
    legend_items <- c(legend_items, paste("LR (AUC =", round(auc(lr_roc), 3), ")"))
    legend_cols <- c(legend_cols, "green")
  }
  
  legend("bottomright", legend = legend_items, col = legend_cols, lwd = 2, cex = 0.8)
}

png("roc_within_dataset.png", width = 12, height = 4, units = "in", res = 300)
par(mfrow = c(1, 3))
plot_within_roc(results_76808, "GSE76808")
plot_within_roc(results_48149, "GSE48149")
plot_within_roc(results_81292, "GSE81292")
dev.off()

# Cross-dataset ROC curves
png("roc_cross_dataset.png", width = 10, height = 6, units = "in", res = 300)
par(mfrow = c(2, 3))
plot(cross_76808_48149$rf_roc, main = "Train: GSE76808 | Test: GSE48149", col = "red", lwd = 2)
legend("bottomright", legend = paste("AUC =", round(auc(cross_76808_48149$rf_roc), 3)))

plot(cross_76808_81292$rf_roc, main = "Train: GSE76808 | Test: GSE81292", col = "red", lwd = 2)
legend("bottomright", legend = paste("AUC =", round(auc(cross_76808_81292$rf_roc), 3)))

plot(cross_48149_76808$rf_roc, main = "Train: GSE48149 | Test: GSE76808", col = "blue", lwd = 2)
legend("bottomright", legend = paste("AUC =", round(auc(cross_48149_76808$rf_roc), 3)))

plot(cross_48149_81292$rf_roc, main = "Train: GSE48149 | Test: GSE81292", col = "blue", lwd = 2)
legend("bottomright", legend = paste("AUC =", round(auc(cross_48149_81292$rf_roc), 3)))

plot(cross_81292_76808$rf_roc, main = "Train: GSE81292 | Test: GSE76808", col = "green", lwd = 2)
legend("bottomright", legend = paste("AUC =", round(auc(cross_81292_76808$rf_roc), 3)))

plot(cross_81292_48149$rf_roc, main = "Train: GSE81292 | Test: GSE48149", col = "green", lwd = 2)
legend("bottomright", legend = paste("AUC =", round(auc(cross_81292_48149$rf_roc), 3)))
dev.off()
```

```{r performance-summary}
# ---- Create Performance Summary Table ----

summary_table <- within_metrics %>%
  mutate(Type = "Within-Dataset CV") %>%
  dplyr::select(Type, Dataset, Model, ROC, Sens, Spec)

cross_summary <- cross_auc %>%
  pivot_longer(cols = c(RF_AUC, SVM_AUC), names_to = "Model", values_to = "ROC") %>%
  mutate(Model = ifelse(Model == "RF_AUC", "Random Forest", "SVM"),
         Type = "Cross-Dataset",
         Dataset = paste(Train, "→", Test)) %>%
  dplyr::select(Type, Dataset, Model, ROC)

cat("\n=== PERFORMANCE SUMMARY ===\n\n")
cat("Within-Dataset Cross-Validation:\n")
print(summary_table)

cat("\n\nCross-Dataset Validation (most rigorous):\n")
print(cross_summary)

# Calculate average cross-dataset performance
avg_cross <- cross_summary %>%
  group_by(Model) %>%
  summarize(Mean_AUC = mean(ROC), SD_AUC = sd(ROC))

cat("\n\nAverage Cross-Dataset Performance:\n")
print(avg_cross)

# Save summary tables
write.csv(summary_table, "within_dataset_performance.csv", row.names = FALSE)
write.csv(cross_summary, "cross_dataset_performance.csv", row.names = FALSE)
write.csv(importance_scores, "gene_importance_scores.csv", row.names = FALSE)

cat("\n✓ All results saved to CSV files\n")
cat("✓ Plots saved as PNG files\n")
```

# Interpretation Guide:
#
# 1. **Within-Dataset CV**: How well can we classify samples from the same study?
#    - High AUC (>0.9): Excellent classifier
#    - Medium AUC (0.7-0.9): Good classifier
#    - Low AUC (<0.7): Poor classifier
#
# 2. **Cross-Dataset Validation**: Can a model trained on one study predict another?
#    - This is the GOLD STANDARD for biomarker validation
#    - If AUC is still high (>0.8), your biomarkers generalize well
#    - If AUC drops significantly, there may be batch effects or study-specific patterns
#
# 3. **Feature Importance**: Which genes matter most?
#    - Top genes = best biomarker candidates
#    - Check where your 8 genes of interest rank
#    - Top genes you didn't expect = potential novel biomarkers!
#
# 4. **Key Questions to Answer**:
#    - Do your 8 genes of interest appear in the top 20-50 most important features?
#    - Are there unexpected genes with high importance?
#    - Does the model generalize across datasets (cross-dataset AUC > 0.7)?
#    - Which dataset combination works best for cross-validation?
#
# 5. **Next Steps**:
#    - Build a gene signature score using top 5-10 genes
#    - Compare your top genes to literature
#    - Validate top novel candidates experimentally